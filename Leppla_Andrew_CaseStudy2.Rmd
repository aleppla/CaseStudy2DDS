---
title: "DDS Project2"
author: "Andrew Leppla"
date: "3/30/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r import, include=FALSE}

CaseStudy2 <- read.csv("C:/Users/aleppla/GitRepos/MDS-6306-Doing-Data-Science/Unit 14 and 15 Case Study 2/CaseStudy2-data.csv",header=T)

#install.packages("onewaytests")
library(onewaytests)
library(tidyverse)
```

```{r EDA Continuous Variables, include=FALSE}

summary(CaseStudy2)


# Variables with no information, drop from dataset
## EmployeeCount is all 1's
## All 870 employees are Over18 (all 1's)
## StandardHours is all 80's across the board
CaseStudy2=CaseStudy2[,-c(10,23,28)]


# Some Continuous Variables vs. MonthlyIncome and Attrition

pairs(CaseStudy2[,c(19,2,5,7,13,20,21,23)],col=CaseStudy2$Attrition)

# MonthlyIncome and Age are visually correlated for regression model
cor(CaseStudy2$Age,CaseStudy2$MonthlyIncome) # r=0.48

# MonthlyIncome shows some decent color separation for predicting Attrition
hist(CaseStudy2$MonthlyIncome) ## Right-skewed distribution


# More Continuous "Years" Variables vs. Monthly Income (and Attrition)

pairs(CaseStudy2[,c(19,2,27:28,30:33)],col=CaseStudy2$Attrition)
# "Years" Variables are partially correlated
pairs(CaseStudy2[,c(27,30:33)],col=CaseStudy2$Attrition)

cor(CaseStudy2[,c(19,2,27,30:33)])
# TotalWorkingYears is the single best predictor, r=0.78
# Everything is partially correlated = Multicollinearity
# Age + YearsAtCompany look like the best 2 predictors to try together

plot(MonthlyIncome~TotalWorkingYears,data=CaseStudy2)
# Bands for Income by Total Years Working: 0,1,2-3,4-5,6-8,9-20,21-40 years
## Recode as categorical
# Income "boundaries" around 1,500 and 20,000 (not continuous)



hist(CaseStudy2$TotalWorkingYears) # right skewed
hist(CaseStudy2$TotalWorkingYears,breaks=40)

# Change 0s to 0.5 for log transform
zeros=grep("\\b0\\b",CaseStudy2$TotalWorkingYears)
CaseStudy2$TotalWorkingYears[zeros]=0.5
summary(CaseStudy2$TotalWorkingYears)
CaseStudy2$log_TWYrs=log(CaseStudy2$TotalWorkingYears)
summary(CaseStudy2$log_TWYrs) # No NA values
CaseStudy2$TotalWorkingYears[zeros]=0 #Change original data back

plot(MonthlyIncome~log_TWYrs,data=CaseStudy2) # exponential
plot(log(MonthlyIncome)~log_TWYrs,data=CaseStudy2)
```

```{r EDA Continuous/Factor Variables, include=FALSE}

# Factors with 2-4 levels coded as integers

pairs(CaseStudy2[,c(19,8,11,14,15,17)],col=CaseStudy2$Attrition)
# MonthlyIncome and JobLevel are strongly correlated, r=0.95
pairs(CaseStudy2[,c(19,15,27,30:33)],col=CaseStudy2$Attrition)
cor(CaseStudy2[,c(19,15,2,27,30:33)])
# JobLevel is partially correlated with other predictors

pairs(CaseStudy2[,c(19,21,24:26,28:29)],col=CaseStudy2$Attrition)


```

```{r EDA Categorical Variables, include=FALSE}

# Categorical Factors  

par(mfrow=c(3,3))
boxplot(MonthlyIncome~BusinessTravel,data=CaseStudy2)
boxplot(MonthlyIncome~Department,data=CaseStudy2) #Minor Effect
boxplot(MonthlyIncome~EducationField,data=CaseStudy2) #Minor Effect
boxplot(MonthlyIncome~Gender,data=CaseStudy2)
boxplot(MonthlyIncome~JobRole,data=CaseStudy2) # Biggest Factor
boxplot(MonthlyIncome~MaritalStatus,data=CaseStudy2)
boxplot(MonthlyIncome~OverTime,data=CaseStudy2)
boxplot(MonthlyIncome~Attrition,data=CaseStudy2) #Minor Effect
par(mfrow=c(1,1))

# Data aren't balanced for JobLevel vs. JobRole, partially confounded

CaseStudy2 %>% ggplot(aes(JobLevel,MonthlyIncome,col=JobRole)) + geom_count() + geom_smooth(method="lm")

CaseStudy2 %>% ggplot(aes(JobRole,MonthlyIncome,col=JobLvl)) + geom_count()

# Combine levels for Income regression?
## Manager and Research Director: Job Levels 3-5
## Manufacturing Director, Healthcare Representative, Sales Executive: Job Levels 2-4
## Research Scientist, Human Resources: Job Levels 1-3
## Laboratory Technician: Job Levels 1-3
## Sales Representative: Job Levels 1-2

# Job Level 2 has the most variation, need more variables


CaseStudy2 %>% filter(JobLevel==2) %>% ggplot(aes(EducationField,MonthlyIncome,col=JobRole)) + geom_count()
#Marketing is 100% counfounded with Sales Executive

```


```{r Training-Test Split, include=F}

set.seed(11133)
index=sample(1:dim(CaseStudy2)[1],dim(CaseStudy2)[1]*0.7,replace=F)
train_CS2=CaseStudy2[index,]
test_CS2=CaseStudy2[-index,]

summary(train_CS2$Attrition)[2]/dim(train_CS2)[1] # 17% yes's
summary(test_CS2$Attrition)[2]/dim(test_CS2)[1] # 14% yes's

summary(train_CS2)
summary(test_CS2)

```


## kNN Prediction of Attrition

K Nearest Neighbors (kNN) was used to predict Attrition.  Monthly Income, Monthly Rate, and Daily Rate together predicted Attrition with 85% Accuracy overall.  This model correctly predicts if an employee will stay (Attrition="no") 85% of the time (sensitivity), and it correctly predicts if an employee with leave (Attrition="yes")  75% of the time (specificity).


```{r kNN}

library(class)

# Best guess from pairs plots
k1=knn(train_CS2[,c(19,5)], test_CS2[,c(19,5)], train_CS2$Attrition , prob=T, k = 13)
CM1=confusionMatrix(table(test_CS2$Attrition,k1)) # 86/50 sens/spec
# Need to add predictor(s) to get Specificity > 60%

# Add all cont. variables that had some visual separation from pairs plots
k_dump1=knn(train_CS2[,c(19,2,5,7,13,20,21,23)], test_CS2[,c(19,2,5,7,13,20,21,23)], train_CS2$Attrition , prob=T, k = 9) # k=9 is best local value
CM_dump1=confusionMatrix(table(test_CS2$Attrition,k_dump1)) # 87/75 sens/spec
# Goal achieved, but which ones are 

# Eliminate variables one-by-one to see what is significant
# Keep: Monthly Income, DailyRate, Monthly Rate
k2=knn(train_CS2[,c(19,5,20)], test_CS2[,c(19,5,20)], train_CS2$Attrition , prob=T, k = 9) # 9 is best local k
CM2=confusionMatrix(table(test_CS2$Attrition,k2)) # 87/75 sens/spec
CM2

# Add all remaining variables to see if it improves
k_dump2=knn(train_CS2[,c(19,5,20,8,11,14,15,17,21,24:26,28,29,30:33)], test_CS2[,c(19,5,20,8,11,14,15,17,21,24:26,28,29,30:33)], train_CS2$Attrition , prob=T, k = 9) # 9 is best local k
CM_dump2=confusionMatrix(table(test_CS2$Attrition,k_dump2)) # 87/75
# No Improvement


# Fit Final Model to Full Data Set

k3=knn(CaseStudy2[,c(19,5,20)], CaseStudy2[,c(19,5,20)], CaseStudy2$Attrition , prob=T, k = 9)
CM3=confusionMatrix(table(CaseStudy2$Attrition,k3)) # 85/75
CM3

#Create a colored 3D Visualization of the kNN Model
pairs(train_CS2[,c(19,5,20)],col=train_CS2$Attrition)
title("Training Set")
pairs(test_CS2[,c(19,5,20)],col=train_CS2$Attrition)
title("Test Set")

```


## Regression Prediction of Monthly Salary

Regression was used to predict Monthly Salary.  Job Level alone predicted Monthly Salary very well with an average error (RMSE) of approximately $1,250 and an R-squared value of 97%.  Mean Monthly Salary increases (non-linearly) as Job Level increases from 1 to 4.  This is a simple, effective, practical model.  

Job Level is strongly related to Job Role as follows:

## Manager and Research Director: Job Levels 3-5
## Manufacturing Director, Healthcare Representative, Sales Executive: Job Levels 2-4
## Research Scientist, Human Resources: Job Levels 1-3
## Laboratory Technician: Job Levels 1-3
## Sales Representative: Job Levels 1-2

```{r Salary Regression CV}

# Linear Model (lm) with JobLevel as numeric
lm1=lm(MonthlyIncome~JobLevel,data=train_CS2)
summary(lm1) #Rsq = 90.6%

# Check Residuals
par(mfrow=c(2,2))
plot(lm1,which=1) # Curvature and non-constant variance
plot(lm1,which=2) # Residuals not normal, ok since n>30
plot(lm1,which=4) # Ok
plot(lm1,which=5) # Ok
par(mfrow=c(1,1))

# Recode JobLevel as factor to fix curvature in residuals
CaseStudy2$JobLvl=as.factor(CaseStudy2$JobLevel)

# Linear Model (lm) with JobLevel as factor
lm1f=lm(MonthlyIncome~JobLvl,data=train_CS2)
summary(lm1f) #Rsq = 92.5%

# Check Residuals
par(mfrow=c(2,2))
plot(lm1f,which=1) # Non-constant variance
plot(lm1f,which=2) # Ok since n>30
plot(lm1f,which=4) # Ok
plot(lm1f,which=5) # Ok
par(mfrow=c(1,1))


# Brown Forsythe non-constant variance test
bf.test(MonthlyIncome~JobLvl,data=CaseStudy2)

# Welch's test of multiple levels with non-constant variance
oneway.test(MonthlyIncome~JobLvl,data=CaseStudy2,var.equal=F)

# Kruskal-Wallance non-parametric test of multiple levels
kruskal.test(MonthlyIncome~JobLvl,data=CaseStudy2)
```

Non-constant variance in residuals is still an issue. Use weighted least squares or unequal variance method(s).


```{r Weighted Least Squares}

# Calculate and populate weights of 1/variance
weight=CaseStudy2 %>% group_by(JobLvl) %>%
  summarize("weight"=1/var(MonthlyIncome))
weight=as.data.frame(weight)
CaseStudy2=merge(CaseStudy2,weight,by="JobLvl")
CaseStudy2=CaseStudy2[order(CaseStudy2$ID),]

# Rerun Training-Test Split to get weights
set.seed(11133)
index=sample(1:dim(CaseStudy2)[1],dim(CaseStudy2)[1]*0.7,replace=F)
train_CS2=CaseStudy2[index,]
test_CS2=CaseStudy2[-index,]


# Weighted Linear Model vs. JobLvl factor
lm1f_wtd = lm(MonthlyIncome~JobLvl,data=train_CS2,weights=weight)
summary(lm1_wtd) # Rsq=97%
# Compared to lm1f, weights don't change the Coefficient Estimates 
# for the factor levels, doesn't fix the underlying variance issue


# Weighted Linear Model vs. JobLevel numeric
lm1_wtd = lm(MonthlyIncome~JobLevel,data=train_CS2,weights=weight)
summary(lm1_wtd) # Rsq=96%
# Compared to lm1, weights change the Coefficient Estimates

par(mfrow=c(1,2))
plot(lm1_wtd,which=1) # Non-weighted residuals
plot(weighted.residuals(lm1_wtd)~lm1_wtd$fitted.values)
title("Weighted Residuals vs Fitted")
# Still curvature in weighted residuals


# Weighted Quadratic Model vs. JobLevel numeric
qm1_wtd = lm(MonthlyIncome~JobLevel+I(JobLevel^2),data=train_CS2,weights=weight)
summary(qm1_wtd) # Rsq=97.1%

# Check curvature of residuals vs. fits 
par(mfrow=c(1,2))
plot(qm1_wtd,which=1) # Non-weighted residuals
plot(weighted.residuals(qm1_wtd)~qm1_wtd$fitted.values)
title("Weighted Residuals vs Fitted")
# Still some curvature 

# Check All Residuals
## GLM uses weighted residuals by default
glm1_wtd = glm(MonthlyIncome~JobLevel+I(JobLevel^2),data=train_CS2,weights=weight)
par(mfrow=c(2,2))
plot(glm1_wtd,which=1) # Could fit cubic
plot(glm1_wtd,which=2) # Ok with n>30
plot(glm1_wtd,which=4) # Ok
plot(glm1_wtd,which=5) # Ok
par(mfrow=c(1,1))


# Weighted Cubic Model vs. JobLevel numeric
cm1_wtd = lm(MonthlyIncome~JobLevel+I(JobLevel^2)+I(JobLevel^3),data=train_CS2,weights=weight)
summary(cm1_wtd) # Rsq=97.2%, little improvement

#Check Residuals
glm3_wtd = glm(MonthlyIncome~JobLevel+I(JobLevel^2)+I(JobLevel^3),data=train_CS2,weights=weight)
par(mfrow=c(2,2))
plot(glm3_wtd,which=1) # Ok, slight upward trend
plot(glm3_wtd,which=2) # Ok with n>30
plot(glm3_wtd,which=4) # Ok
plot(glm3_wtd,which=5) # Ok
par(mfrow=c(1,1))
```

## RMSE Calculations

``` {r RMSE}
 
Train_RMSE=c()
Test_RMSE=c()

# JobLevel Quadratic
qm1_train_pred = predict(qm1_wtd, newdata = train_CS2)
qm1_test_pred = predict(qm1_wtd, newdata = test_CS2)
Train_RMSE[1] = sqrt(mean((train_CS2$MonthlyIncome - qm1_train_pred)^2))
Test_RMSE[1] = sqrt(mean((test_CS2$MonthlyIncome - qm1_test_pred)^2))

# JobLevel Cubic
cm1_train_pred = predict(cm1_wtd, newdata = train_CS2)
cm1_test_pred = predict(cm1_wtd, newdata = test_CS2)
Train_RMSE[2] = sqrt(mean((train_CS2$MonthlyIncome - cm1_train_pred)^2))
Test_RMSE[2] = sqrt(mean((test_CS2$MonthlyIncome - cm1_test_pred)^2))

# JobLvl Factor
lm1f_train_pred = predict(lm1f, newdata = train_CS2)
lm1f_test_pred = predict(lm1f, newdata = test_CS2)
Train_RMSE[3] = sqrt(mean((train_CS2$MonthlyIncome - lm1_train_pred)^2))
Test_RMSE[3] = sqrt(mean((test_CS2$MonthlyIncome - lm1_test_pred)^2))

RMSE = data.frame(c("Quadratic","Cubic","Factor"),Train_RMSE,Test_RMSE)
names(RMSE)=c("JobLevel_Model","Training_RMSE", "Test_RMSE")
RMSE

```

## Fit Final Model to Full Data Set

```{r Final Reg Model}
lm.final = lm(MonthlyIncome~JobLevel+I(JobLevel^2)+I(JobLevel^3),data=CaseStudy2,weights=weight)
summary(lm.final) # Rsq=97.2% 

#Check Residuals
glm.final = glm(MonthlyIncome~JobLevel+I(JobLevel^2)+I(JobLevel^3),data=CaseStudy2,weights=weight)
par(mfrow=c(2,2))
plot(glm.final,which=1) # 
plot(glm.final,which=2) # Ok with n>30
plot(glm.final,which=4) # Ok
plot(glm.final,which=5) # Ok
par(mfrow=c(1,1))

lm.final.pred = predict(lm.final, newdata = CaseStudy2)
Final_RMSE=sqrt(mean((CaseStudy2$MonthlyIncome - lm.final.pred)^2))
Final_RMSE

##################################################
# Visualize the Model

plot(CaseStudy2$JobLevel,CaseStudy2$MonthlyIncome)


```


```{r LDA}
library(MASS)
library(caret)

my_lda1 <- lda(Attrition ~ MonthlyIncome, data = CaseStudy2,CV=T,prior=c(0.53,0.47))
CM_1 = confusionMatrix(table(my_lda1$class,CaseStudy2$Attrition))
CM_1
# 60% sensitivity and specificity

my_lda2 <- lda(Attrition ~ MonthlyIncome + PerformanceRating, data = CaseStudy2,CV=T)
CM_2 = confusionMatrix(table(my_lda2$class,CaseStudy2$Attrition))
CM_2
# 60% sensitivity and specificity


```


